{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb549c80-3993-4c0d-8dcc-8e93e9432fe4",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c393352-b235-482c-9ff9-f21b6603026c",
   "metadata": {},
   "source": [
    "- PEFT technique = Low Rank Adaption (LoRA)\n",
    "- Model = GPT2\n",
    "- Evaluation approach = Hugging Face Train / Evaluate loops\n",
    "- Fine-tuning dataset = https://huggingface.co/datasets/cornell-movie-review-data/rotten_tomatoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2096bc-f6f7-4911-8fa0-187dffa255a4",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd271e37-fc8c-4d11-9ce4-b1f6072400ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from peft import AutoPeftModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c9688-f7ed-4630-940a-3b58d163d755",
   "metadata": {},
   "source": [
    "## Load A Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa07027-e8f5-47de-8526-e77a14a259c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/cornell-movie-review-data/rotten_tomatoes\n",
    "# https://huggingface.co/docs/hub/datasets-usage\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "review_data = {split: ds for split, ds in zip(splits, load_dataset(\"cornell-movie-review-data/rotten_tomatoes\", split=splits))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8e262-766f-4bf5-82ae-52d9f375db52",
   "metadata": {},
   "source": [
    "## Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d74903-bb26-4ea5-b96d-c9b0b98ad330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petermatthews/.pyenv/versions/3.11.2/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "# Tokenize train and test sets\n",
    "train_dataset = review_data[\"train\"].map(tokenize, batched=True)\n",
    "test_dataset = review_data[\"test\"].map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c7fee-972b-437f-943e-e83dc7fc6b73",
   "metadata": {},
   "source": [
    "## Load a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6e6d20-919a-4444-b8b5-4a59d5cdc26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
    ")\n",
    "\n",
    "# Freeze all the parameters of the base model\n",
    "for param in base_model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867ed27-cc16-4ee8-ab5b-98c0dfc4df5b",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluation approach: evaluate method with a Hugging Face Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fdf9f61-b85b-4eb0-b326-c565fa7d605a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1067' max='1067' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1067/1067 01:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.824500</td>\n",
       "      <td>0.739076</td>\n",
       "      <td>0.529081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a compute metrics method\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "# Build a Trainer\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/sentiment_analysis\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train and Evaluate\n",
    "trainer.train()\n",
    "base_evaluation = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1265bdb7-cca0-4523-84ee-f0171b7a8384",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca3401b-7f8f-4a2e-a8dc-38065cd3d5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_loss</td>\n",
       "      <td>0.739076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.529081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eval_runtime</td>\n",
       "      <td>5.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eval_samples_per_second</td>\n",
       "      <td>178.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eval_steps_per_second</td>\n",
       "      <td>22.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>epoch</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric     Results\n",
       "0                eval_loss    0.739076\n",
       "1            eval_accuracy    0.529081\n",
       "2             eval_runtime    5.979700\n",
       "3  eval_samples_per_second  178.270000\n",
       "4    eval_steps_per_second   22.409000\n",
       "5                    epoch    1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = pd.DataFrame(base_evaluation.items(), columns=['Metric', 'Results'])\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71f1d12-6939-484f-ba6d-f6b92c01456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing some predictions\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lovingly photographed in the manner of a golde...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>consistently clever and suspenseful .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's like a \" big chill \" reunion of the baade...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the story gives ample opportunity for large-sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red dragon \" never cuts corners .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  predicted_label\n",
       "0  lovingly photographed in the manner of a golde...      1                1\n",
       "1              consistently clever and suspenseful .      1                0\n",
       "2  it's like a \" big chill \" reunion of the baade...      1                1\n",
       "3  the story gives ample opportunity for large-sc...      1                1\n",
       "4                  red dragon \" never cuts corners .      1                1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View some individual results\n",
    "\n",
    "df = pd.DataFrame(test_dataset)\n",
    "df = df[[\"text\", \"label\"]]\n",
    "\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"<br />\", \" \")\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "print(\"Viewing some predictions\\n\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f1557df-e17d-4b77-b412-74d84f35ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing some mistakes\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>consistently clever and suspenseful .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fresnadillo has something serious to say about...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>throws in enough clever and unexpected twists ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>generates an enormous feeling of empathy for i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>. . . quite good at providing some good old fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  predicted_label\n",
       "1               consistently clever and suspenseful .      1                0\n",
       "5   fresnadillo has something serious to say about...      1                0\n",
       "6   throws in enough clever and unexpected twists ...      1                0\n",
       "9   generates an enormous feeling of empathy for i...      1                0\n",
       "13  . . . quite good at providing some good old fa...      1                0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Viewing some mistakes\\n\")\n",
    "\n",
    "df[df[\"label\"] != df[\"predicted_label\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce277d68-6268-49b9-9516-19d3f69f4386",
   "metadata": {},
   "source": [
    "## Try LoRA PEFT and see how we get on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdc9d529-ec74-44f0-980d-44fb9a6fbfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petermatthews/.pyenv/versions/3.11.2/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/Users/petermatthews/.pyenv/versions/3.11.2/lib/python3.11/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setting up PEFT\n",
    "\n",
    "# Define LoRA Config\n",
    "config = LoraConfig(\n",
    "                    r=8, # Rank\n",
    "                    lora_alpha=32,\n",
    "                    target_modules=['c_attn', 'c_proj'],\n",
    "                    lora_dropout=0.1,\n",
    "                    bias=\"none\",\n",
    "                    task_type=TaskType.SEQ_CLS\n",
    "                )\n",
    "\n",
    "# Need a model again\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Build lora adapter\n",
    "lora_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a8577f-d6db-46c5-8401-0c4cfafdff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 812,544 || all params: 125,253,888 || trainable%: 0.6487\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da0053-189f-4ac8-9b9d-e2c8c397bdb4",
   "metadata": {},
   "source": [
    "## Re-evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4802ebbe-2293-428e-a68e-0526bfced648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1067' max='1067' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1067/1067 02:46, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.674700</td>\n",
       "      <td>0.581595</td>\n",
       "      <td>0.700750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a Trainer, again\n",
    "trainer2 = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/peft_sentiment_analysis\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        label_names=['labels']\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "# Train and Evaluate\n",
    "trainer2.train()\n",
    "peft_evaluation = trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "846591a1-ec46-417d-a3e0-40dd9cd4f8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing some predictions\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lovingly photographed in the manner of a golde...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>consistently clever and suspenseful .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's like a \" big chill \" reunion of the baade...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the story gives ample opportunity for large-sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red dragon \" never cuts corners .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  predicted_label\n",
       "0  lovingly photographed in the manner of a golde...      1                1\n",
       "1              consistently clever and suspenseful .      1                1\n",
       "2  it's like a \" big chill \" reunion of the baade...      1                0\n",
       "3  the story gives ample opportunity for large-sc...      1                1\n",
       "4                  red dragon \" never cuts corners .      1                1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View some individual results\n",
    "\n",
    "df = pd.DataFrame(test_dataset)\n",
    "df = df[[\"text\", \"label\"]]\n",
    "\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"<br />\", \" \")\n",
    "\n",
    "predictions = trainer2.predict(test_dataset)\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "print(\"Viewing some predictions\\n\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ecfd1fe-b94c-4ec6-8e44-6e06dc3cd3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing some mistakes\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's like a \" big chill \" reunion of the baade...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>at its worst , the movie is pretty diverting ;...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>as it turns out , you can go home again .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you've already seen city by the sea under a va...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>grown-up quibbles are beside the point here . ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  predicted_label\n",
       "2   it's like a \" big chill \" reunion of the baade...      1                0\n",
       "14  at its worst , the movie is pretty diverting ;...      1                0\n",
       "18          as it turns out , you can go home again .      1                0\n",
       "19  you've already seen city by the sea under a va...      1                0\n",
       "22  grown-up quibbles are beside the point here . ...      1                0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Viewing some mistakes\\n\")\n",
    "\n",
    "df[df[\"label\"] != df[\"predicted_label\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7124ebd-bd26-47d1-a17e-75cdcbaeb45b",
   "metadata": {},
   "source": [
    "## Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f40cfaa-1c6e-47a8-a65e-e5e57822bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.DataFrame(base_evaluation.items(), columns=['Metric', 'Results'])\n",
    "peft_df = pd.DataFrame(peft_evaluation.items(), columns=['Metric', 'Results'])                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f77aa7-bdb8-4835-bee3-b19ad27c840f",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "286b72cc-0277-4935-9db4-a30ae2ea4ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_loss</td>\n",
       "      <td>0.739076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.529081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eval_runtime</td>\n",
       "      <td>5.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eval_samples_per_second</td>\n",
       "      <td>178.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eval_steps_per_second</td>\n",
       "      <td>22.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>epoch</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric     Results\n",
       "0                eval_loss    0.739076\n",
       "1            eval_accuracy    0.529081\n",
       "2             eval_runtime    5.979700\n",
       "3  eval_samples_per_second  178.270000\n",
       "4    eval_steps_per_second   22.409000\n",
       "5                    epoch    1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b47ca9-41a7-4c2d-be15-d28ddb8d1a88",
   "metadata": {},
   "source": [
    "### LORA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab89b595-dfae-4ab7-b609-ed2d265fa5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_loss</td>\n",
       "      <td>0.581595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.700750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eval_runtime</td>\n",
       "      <td>6.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eval_samples_per_second</td>\n",
       "      <td>168.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eval_steps_per_second</td>\n",
       "      <td>21.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>epoch</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric     Results\n",
       "0                eval_loss    0.581595\n",
       "1            eval_accuracy    0.700750\n",
       "2             eval_runtime    6.340900\n",
       "3  eval_samples_per_second  168.114000\n",
       "4    eval_steps_per_second   21.133000\n",
       "5                    epoch    1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e138bbef-c952-4aa6-84ce-d4c341d4c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine tuned PEFT model\n",
    "lora_model.save_pretrained(\"gpt-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78c220-9d54-4638-8338-fa4b0f9372f0",
   "metadata": {},
   "source": [
    "## Loading a locally saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "916afe1c-1d75-403d-a5f9-8be3d9511966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lora_model_local = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt-lora\", \n",
    "    num_labels=2, \n",
    "    ignore_mismatched_sizes=True).to(device)\n",
    "\n",
    "lora_model_local.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf983c-feb6-44b5-b640-a38c79674329",
   "metadata": {},
   "source": [
    "## Evaluate the locally saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90b282bc-3b45-4e3f-9a15-6bb1809078c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1067' max='1067' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1067/1067 01:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.620100</td>\n",
       "      <td>0.559964</td>\n",
       "      <td>0.727955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a Trainer, again, again\n",
    "trainer3 = Trainer(\n",
    "    model=lora_model_local,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/lora_sentiment_analysis\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        label_names=['labels']\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "# Train and Evaluate\n",
    "trainer3.train()\n",
    "lora_evaluation = trainer3.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edec07c5-710e-4277-acee-fb91de3b40fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing some predictions\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lovingly photographed in the manner of a golde...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>consistently clever and suspenseful .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's like a \" big chill \" reunion of the baade...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the story gives ample opportunity for large-sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red dragon \" never cuts corners .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  predicted_label\n",
       "0  lovingly photographed in the manner of a golde...      1                1\n",
       "1              consistently clever and suspenseful .      1                1\n",
       "2  it's like a \" big chill \" reunion of the baade...      1                0\n",
       "3  the story gives ample opportunity for large-sc...      1                1\n",
       "4                  red dragon \" never cuts corners .      1                1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View some individual results\n",
    "\n",
    "df = pd.DataFrame(test_dataset)\n",
    "df = df[[\"text\", \"label\"]]\n",
    "\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"<br />\", \" \")\n",
    "\n",
    "predictions = trainer3.predict(test_dataset)\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "print(\"Viewing some predictions\\n\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4cfb324-54a2-4be6-a907-87da60894c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing some mistakes\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's like a \" big chill \" reunion of the baade...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>at its worst , the movie is pretty diverting ;...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>as it turns out , you can go home again .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you've already seen city by the sea under a va...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>grown-up quibbles are beside the point here . ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  predicted_label\n",
       "2   it's like a \" big chill \" reunion of the baade...      1                0\n",
       "14  at its worst , the movie is pretty diverting ;...      1                0\n",
       "18          as it turns out , you can go home again .      1                0\n",
       "19  you've already seen city by the sea under a va...      1                0\n",
       "22  grown-up quibbles are beside the point here . ...      1                0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Viewing some mistakes\\n\")\n",
    "\n",
    "df[df[\"label\"] != df[\"predicted_label\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed47cffb-dd89-405a-ba7b-5fa0cf41f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_df = pd.DataFrame(lora_evaluation.items(), columns=['Metric', 'Results']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4db181b5-a7ec-4e50-89ab-16cc1f192dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_loss</td>\n",
       "      <td>0.739076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.529081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eval_runtime</td>\n",
       "      <td>5.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eval_samples_per_second</td>\n",
       "      <td>178.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eval_steps_per_second</td>\n",
       "      <td>22.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>epoch</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric     Results\n",
       "0                eval_loss    0.739076\n",
       "1            eval_accuracy    0.529081\n",
       "2             eval_runtime    5.979700\n",
       "3  eval_samples_per_second  178.270000\n",
       "4    eval_steps_per_second   22.409000\n",
       "5                    epoch    1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "543efbdb-d9df-402d-ab83-68c624b9f6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_loss</td>\n",
       "      <td>0.581595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.700750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eval_runtime</td>\n",
       "      <td>6.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eval_samples_per_second</td>\n",
       "      <td>168.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eval_steps_per_second</td>\n",
       "      <td>21.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>epoch</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric     Results\n",
       "0                eval_loss    0.581595\n",
       "1            eval_accuracy    0.700750\n",
       "2             eval_runtime    6.340900\n",
       "3  eval_samples_per_second  168.114000\n",
       "4    eval_steps_per_second   21.133000\n",
       "5                    epoch    1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8683f1de-a201-456c-b003-13287ad955d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_loss</td>\n",
       "      <td>0.559964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.727955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eval_runtime</td>\n",
       "      <td>6.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eval_samples_per_second</td>\n",
       "      <td>167.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eval_steps_per_second</td>\n",
       "      <td>21.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>epoch</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric     Results\n",
       "0                eval_loss    0.559964\n",
       "1            eval_accuracy    0.727955\n",
       "2             eval_runtime    6.365200\n",
       "3  eval_samples_per_second  167.474000\n",
       "4    eval_steps_per_second   21.052000\n",
       "5                    epoch    1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4a707a9-69a8-4405-a803-66a1008a02bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy after first train/eval:  52.91%,\n",
      "Accuracy after adding PEFT and second train/eval: 70.08%,\n",
      "and accuracy after saving, loading and a third train/eval: 72.80%\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = base_df['Results'][1]\n",
    "accuracy2 = peft_df['Results'][1]\n",
    "accuracy3 = lora_df['Results'][1]\n",
    "print('''Base model accuracy after first train/eval:  {:2.2%},\n",
    "Accuracy after adding PEFT and second train/eval: {:2.2%},\n",
    "and accuracy after saving, loading and a third train/eval: {:2.2%}'''.format(accuracy1, accuracy2, accuracy3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c4390-09b1-4f07-872a-015a25f134ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
